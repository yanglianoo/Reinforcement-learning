{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/core.py:26: UserWarning: \u001b[33mWARN: Gym minimally supports python 3.6 as the python foundation not longer supports the version, please update your version to 3.7+\u001b[0m\n",
      "  \"Gym minimally supports python 3.6 as the python foundation not longer supports the version, please update your version to 3.7+\"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  \"The argument mode in render method is deprecated; \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#创建环境\n",
    "env = gym.make('Pendulum-v1')\n",
    "env.reset()\n",
    "\n",
    "\n",
    "#打印游戏\n",
    "def show():\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.336464285850525, -1673.4074745220885)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from IPython import display\n",
    "import math\n",
    "\n",
    "\n",
    "class SAC:\n",
    "    class ModelAction(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.fc_state = torch.nn.Sequential(\n",
    "                torch.nn.Linear(3, 128),\n",
    "                torch.nn.ReLU(),\n",
    "            )\n",
    "            self.fc_mu = torch.nn.Linear(128, 1)\n",
    "            self.fc_std = torch.nn.Sequential(\n",
    "                torch.nn.Linear(128, 1),\n",
    "                torch.nn.Softplus(),\n",
    "            )\n",
    "\n",
    "        def forward(self, state):\n",
    "            #[b, 3] -> [b, 128]\n",
    "            state = self.fc_state(state)\n",
    "\n",
    "            #[b, 128] -> [b, 1]\n",
    "            mu = self.fc_mu(state)\n",
    "\n",
    "            #[b, 128] -> [b, 1]\n",
    "            std = self.fc_std(state)\n",
    "\n",
    "            #根据mu和std定义b个正态分布\n",
    "            dist = torch.distributions.Normal(mu, std)\n",
    "\n",
    "            #采样b个样本\n",
    "            #这里用的是rsample,表示重采样,其实就是先从一个标准正态分布中采样,然后乘以标准差,加上均值\n",
    "            sample = dist.rsample()\n",
    "\n",
    "            #样本压缩到-1,1之间,求动作\n",
    "            action = torch.tanh(sample)\n",
    "\n",
    "            #求概率对数\n",
    "            log_prob = dist.log_prob(sample)\n",
    "\n",
    "            #这个式子看不懂,但参照上下文理解,这个值应该描述的是动作的熵\n",
    "            entropy = log_prob - (1 - action.tanh()**2 + 1e-7).log()\n",
    "            entropy = -entropy\n",
    "\n",
    "            return action * 2, entropy\n",
    "\n",
    "    class ModelValue(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.sequential = torch.nn.Sequential(\n",
    "                torch.nn.Linear(4, 128),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(128, 128),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(128, 1),\n",
    "            )\n",
    "\n",
    "        def forward(self, state, action):\n",
    "            #[b, 3+1] -> [b, 4]\n",
    "            state = torch.cat([state, action], dim=1)\n",
    "\n",
    "            #[b, 4] -> [b, 1]\n",
    "            return self.sequential(state)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_action = self.ModelAction()\n",
    "\n",
    "        self.model_value1 = self.ModelValue()\n",
    "        self.model_value2 = self.ModelValue()\n",
    "\n",
    "        self.model_value_next1 = self.ModelValue()\n",
    "        self.model_value_next2 = self.ModelValue()\n",
    "\n",
    "        self.model_value_next1.load_state_dict(self.model_value1.state_dict())\n",
    "        self.model_value_next2.load_state_dict(self.model_value2.state_dict())\n",
    "\n",
    "        #这也是一个可学习的参数\n",
    "        self.alpha = torch.tensor(math.log(0.01))\n",
    "        self.alpha.requires_grad = True\n",
    "\n",
    "        self.optimizer_action = torch.optim.Adam(\n",
    "            self.model_action.parameters(), lr=3e-4)\n",
    "        self.optimizer_value1 = torch.optim.Adam(\n",
    "            self.model_value1.parameters(), lr=3e-3)\n",
    "        self.optimizer_value2 = torch.optim.Adam(\n",
    "            self.model_value2.parameters(), lr=3e-3)\n",
    "\n",
    "        #alpha也是要更新的参数,所以这里要定义优化器\n",
    "        self.optimizer_alpha = torch.optim.Adam([self.alpha], lr=3e-4)\n",
    "\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).reshape(1, 3)\n",
    "        action, _ = self.model_action(state)\n",
    "        return action.item()\n",
    "\n",
    "    def test(self, play):\n",
    "        #初始化游戏\n",
    "        state = env.reset()\n",
    "\n",
    "        #记录反馈值的和,这个值越大越好\n",
    "        reward_sum = 0\n",
    "\n",
    "        #玩到游戏结束为止\n",
    "        over = False\n",
    "        while not over:\n",
    "            #根据当前状态得到一个动作\n",
    "            action = self.get_action(state)\n",
    "\n",
    "            #执行动作,得到反馈\n",
    "            state, reward, over, _ = env.step([action])\n",
    "            reward_sum += reward\n",
    "\n",
    "            #打印动画\n",
    "            if play and random.random() < 0.2:  #跳帧\n",
    "                display.clear_output(wait=True)\n",
    "                show()\n",
    "\n",
    "        return reward_sum\n",
    "\n",
    "    def _soft_update(self, model, model_next):\n",
    "        for param, param_next in zip(model.parameters(),\n",
    "                                     model_next.parameters()):\n",
    "            #以一个小的比例更新\n",
    "            value = param_next.data * 0.995 + param.data * 0.005\n",
    "            param_next.data.copy_(value)\n",
    "\n",
    "    def _get_target(self, reward, next_state, over):\n",
    "        #首先使用model_action计算动作和动作的熵\n",
    "        #[b, 4] -> [b, 1],[b, 1]\n",
    "        action, entropy = self.model_action(next_state)\n",
    "\n",
    "        #评估next_state的价值\n",
    "        #[b, 4],[b, 1] -> [b, 1]\n",
    "        target1 = self.model_value_next1(next_state, action)\n",
    "        target2 = self.model_value_next2(next_state, action)\n",
    "\n",
    "        #取价值小的,这是出于稳定性考虑\n",
    "        #[b, 1]\n",
    "        target = torch.min(target1, target2)\n",
    "\n",
    "        #exp和log互为反操作,这里是把alpha还原了\n",
    "        #这里的操作是在target上加上了动作的熵,alpha作为权重系数\n",
    "        #[b, 1] - [b, 1] -> [b, 1]\n",
    "        target += self.alpha.exp() * entropy\n",
    "\n",
    "        #[b, 1]\n",
    "        target *= 0.99\n",
    "        target *= (1 - over)\n",
    "        target += reward\n",
    "\n",
    "        return target\n",
    "\n",
    "    def _get_loss_action(self, state):\n",
    "        #计算action和熵\n",
    "        #[b, 3] -> [b, 1],[b, 1]\n",
    "        action, entropy = self.model_action(state)\n",
    "\n",
    "        #使用两个value网络评估action的价值\n",
    "        #[b, 3],[b, 1] -> [b, 1]\n",
    "        value1 = self.model_value1(state, action)\n",
    "        value2 = self.model_value2(state, action)\n",
    "\n",
    "        #取价值小的,出于稳定性考虑\n",
    "        #[b, 1]\n",
    "        value = torch.min(value1, value2)\n",
    "\n",
    "        #alpha还原后乘以熵,这个值期望的是越大越好,但是这里是计算loss,所以符号取反\n",
    "        #[1] - [b, 1] -> [b, 1]\n",
    "        loss_action = -self.alpha.exp() * entropy\n",
    "\n",
    "        #减去value,所以value越大越好,这样loss就会越小\n",
    "        loss_action -= value\n",
    "\n",
    "        return loss_action.mean(), entropy\n",
    "\n",
    "    def _get_loss_value(self, model_value, target, state, action, next_state):\n",
    "        #计算value\n",
    "        value = model_value(state, action)\n",
    "\n",
    "        #计算loss,value的目标是要贴近target\n",
    "        loss_value = self.loss_fn(value, target)\n",
    "        return loss_value\n",
    "\n",
    "    def train(self, state, action, reward, next_state, over):\n",
    "        #对reward偏移,为了便于训练\n",
    "        reward = (reward + 8) / 8\n",
    "\n",
    "        #计算target,这个target里已经考虑了动作的熵\n",
    "        #[b, 1]\n",
    "        target = self._get_target(reward, next_state, over)\n",
    "        target = target.detach()\n",
    "\n",
    "        #计算两个value loss\n",
    "        loss_value1 = self._get_loss_value(self.model_value1, target, state,\n",
    "                                           action, next_state)\n",
    "        loss_value2 = self._get_loss_value(self.model_value2, target, state,\n",
    "                                           action, next_state)\n",
    "\n",
    "        #更新参数\n",
    "        self.optimizer_value1.zero_grad()\n",
    "        loss_value1.backward()\n",
    "        self.optimizer_value1.step()\n",
    "\n",
    "        self.optimizer_value2.zero_grad()\n",
    "        loss_value2.backward()\n",
    "        self.optimizer_value2.step()\n",
    "\n",
    "        #使用model_value计算model_action的loss\n",
    "        loss_action, entropy = self._get_loss_action(state)\n",
    "        self.optimizer_action.zero_grad()\n",
    "        loss_action.backward()\n",
    "        self.optimizer_action.step()\n",
    "\n",
    "        #熵乘以alpha就是alpha的loss\n",
    "        #[b, 1] -> [1]\n",
    "        loss_alpha = (entropy + 1).detach() * self.alpha.exp()\n",
    "        loss_alpha = loss_alpha.mean()\n",
    "\n",
    "        #更新alpha值\n",
    "        self.optimizer_alpha.zero_grad()\n",
    "        loss_alpha.backward()\n",
    "        self.optimizer_alpha.step()\n",
    "\n",
    "        #增量更新next模型\n",
    "        self._soft_update(self.model_value1, self.model_value_next1)\n",
    "        self._soft_update(self.model_value2, self.model_value_next2)\n",
    "\n",
    "\n",
    "teacher = SAC()\n",
    "\n",
    "teacher.train(\n",
    "    torch.randn(5, 3),\n",
    "    torch.randn(5, 1),\n",
    "    torch.randn(5, 1),\n",
    "    torch.randn(5, 3),\n",
    "    torch.zeros(5, 1).long(),\n",
    ")\n",
    "\n",
    "teacher.get_action([1, 2, 3]), teacher.test(play=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811701593/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " (tensor([[-8.4779e-01,  5.3034e-01, -3.5261e+00],\n",
       "          [-9.5679e-01,  2.9079e-01,  1.7123e+00],\n",
       "          [-9.7316e-01,  2.3014e-01,  1.7876e+00],\n",
       "          [-1.0000e+00, -1.5998e-03, -2.7741e+00],\n",
       "          [-9.8945e-01,  1.4490e-01, -2.0452e+00],\n",
       "          [-7.1142e-01, -7.0276e-01, -1.1076e+00],\n",
       "          [-9.9264e-01,  1.2110e-01,  3.1162e+00],\n",
       "          [-7.5955e-01,  6.5045e-01, -2.9836e+00],\n",
       "          [-8.5398e-01, -5.2030e-01,  1.3258e+00],\n",
       "          [-9.9661e-01, -8.2295e-02,  1.8541e+00],\n",
       "          [-9.9215e-01,  1.2509e-01, -2.5741e+00],\n",
       "          [-5.1163e-01,  8.5921e-01,  8.5005e-01],\n",
       "          [-9.9581e-01, -9.1469e-02,  2.1893e+00],\n",
       "          [-8.3963e-01,  5.4315e-01,  2.2816e-01],\n",
       "          [-9.2155e-01, -3.8826e-01,  1.8021e+00],\n",
       "          [-9.9948e-01,  3.2346e-02, -3.2011e+00],\n",
       "          [-6.6742e-01,  7.4468e-01, -2.6376e+00],\n",
       "          [-8.4106e-01,  5.4095e-01,  6.2552e-01],\n",
       "          [-9.9907e-01,  4.3144e-02, -2.2756e+00],\n",
       "          [-9.4540e-01, -3.2590e-01,  2.4708e+00],\n",
       "          [-9.9915e-01, -4.1227e-02, -1.7377e+00],\n",
       "          [-9.9103e-01,  1.3367e-01,  1.9630e+00],\n",
       "          [-8.5300e-01,  5.2191e-01, -1.0673e+00],\n",
       "          [-9.5257e-01,  3.0431e-01, -1.5643e+00],\n",
       "          [-9.0603e-01, -4.2322e-01,  2.1006e+00],\n",
       "          [-8.6152e-01,  5.0772e-01,  1.9763e+00],\n",
       "          [-6.9714e-01, -7.1694e-01, -9.4517e-01],\n",
       "          [-6.6757e-01, -7.4455e-01,  1.1370e+00],\n",
       "          [-9.2696e-01,  3.7517e-01, -1.5074e+00],\n",
       "          [-9.5275e-01, -3.0376e-01,  2.2509e+00],\n",
       "          [-8.7643e-01,  4.8153e-01,  3.6924e+00],\n",
       "          [-7.8846e-01, -6.1509e-01, -6.0221e-01],\n",
       "          [-8.6954e-01,  4.9387e-01,  3.8661e-01],\n",
       "          [-9.1214e-01,  4.0987e-01, -1.5779e+00],\n",
       "          [-8.9264e-01,  4.5078e-01,  1.0408e+00],\n",
       "          [-4.6292e-01,  8.8640e-01, -4.6979e-01],\n",
       "          [-9.4615e-01, -3.2374e-01,  2.9283e+00],\n",
       "          [-7.9269e-01, -6.0962e-01, -8.3781e-02],\n",
       "          [-9.1629e-01,  4.0052e-01,  1.2485e+00],\n",
       "          [-9.6098e-01, -2.7660e-01, -2.6422e+00],\n",
       "          [-6.9643e-01,  7.1763e-01,  7.6824e-02],\n",
       "          [-9.7492e-01, -2.2255e-01, -1.5073e+00],\n",
       "          [-8.5012e-01,  5.2659e-01,  5.8681e-01],\n",
       "          [-8.7734e-01,  4.7987e-01, -1.0165e+00],\n",
       "          [-9.5595e-01, -2.9352e-01, -2.9979e+00],\n",
       "          [-9.9367e-01,  1.1234e-01,  2.0635e+00],\n",
       "          [-7.6371e-01,  6.4556e-01, -1.8363e+00],\n",
       "          [-9.7836e-01, -2.0692e-01,  2.3366e+00],\n",
       "          [-9.1897e-01,  3.9434e-01,  1.2457e+00],\n",
       "          [ 5.4016e-03, -9.9999e-01, -1.8671e+00],\n",
       "          [-9.8159e-01, -1.9100e-01,  1.9891e+00],\n",
       "          [-8.5927e-01, -5.1152e-01,  1.9991e+00],\n",
       "          [-9.7961e-01,  2.0089e-01,  1.8556e+00],\n",
       "          [-7.3149e-01, -6.8185e-01,  1.7630e+00],\n",
       "          [-9.0140e-01, -4.3298e-01, -2.5946e+00],\n",
       "          [-8.3503e-01,  5.5020e-01, -5.8317e-01],\n",
       "          [ 9.8597e-02, -9.9513e-01, -1.2288e+00],\n",
       "          [-8.8657e-01, -4.6259e-01,  1.6436e+00],\n",
       "          [-7.8868e-01, -6.1481e-01,  2.3983e+00],\n",
       "          [-7.4712e-01, -6.6469e-01, -1.4463e+00],\n",
       "          [-6.6737e-01,  7.4472e-01,  2.3615e+00],\n",
       "          [-9.9999e-01, -3.2869e-03, -2.5850e+00],\n",
       "          [-8.5072e-01,  5.2562e-01, -1.1902e+00],\n",
       "          [-8.5656e-01, -5.1604e-01,  2.9903e+00]]),\n",
       "  tensor([[ 0.9649],\n",
       "          [-0.4986],\n",
       "          [ 0.0191],\n",
       "          [-0.1388],\n",
       "          [ 1.4990],\n",
       "          [-1.5064],\n",
       "          [-1.7556],\n",
       "          [-0.9452],\n",
       "          [ 0.6678],\n",
       "          [ 0.9718],\n",
       "          [ 0.4309],\n",
       "          [ 0.1072],\n",
       "          [ 1.4391],\n",
       "          [ 1.3206],\n",
       "          [ 0.8843],\n",
       "          [-0.4582],\n",
       "          [-0.7956],\n",
       "          [-1.3047],\n",
       "          [ 1.3203],\n",
       "          [-0.8382],\n",
       "          [-1.5769],\n",
       "          [ 1.0305],\n",
       "          [ 0.1600],\n",
       "          [-1.1421],\n",
       "          [ 1.4394],\n",
       "          [ 0.5424],\n",
       "          [ 0.2436],\n",
       "          [-1.9429],\n",
       "          [-0.5077],\n",
       "          [-1.4730],\n",
       "          [-1.8806],\n",
       "          [-1.3297],\n",
       "          [-1.8199],\n",
       "          [-1.0794],\n",
       "          [-0.8876],\n",
       "          [ 0.4719],\n",
       "          [ 1.7126],\n",
       "          [ 1.3633],\n",
       "          [-0.8965],\n",
       "          [ 0.3376],\n",
       "          [ 0.4368],\n",
       "          [-1.6781],\n",
       "          [-1.8912],\n",
       "          [ 0.3164],\n",
       "          [-1.2399],\n",
       "          [-0.6839],\n",
       "          [ 1.7243],\n",
       "          [ 1.9295],\n",
       "          [ 0.8894],\n",
       "          [ 1.9397],\n",
       "          [-1.9746],\n",
       "          [-1.7941],\n",
       "          [-1.0472],\n",
       "          [ 1.4645],\n",
       "          [-0.5237],\n",
       "          [ 0.9612],\n",
       "          [ 0.7200],\n",
       "          [ 0.1942],\n",
       "          [-1.1613],\n",
       "          [ 1.1870],\n",
       "          [ 0.9469],\n",
       "          [ 0.0890],\n",
       "          [ 1.4187],\n",
       "          [-1.3663]]),\n",
       "  tensor([[ -7.9141],\n",
       "          [ -8.3962],\n",
       "          [ -8.7840],\n",
       "          [-10.6291],\n",
       "          [ -9.3976],\n",
       "          [ -5.7055],\n",
       "          [-10.0957],\n",
       "          [ -6.8126],\n",
       "          [ -6.9071],\n",
       "          [ -9.7034],\n",
       "          [ -9.7601],\n",
       "          [ -4.5154],\n",
       "          [ -9.7838],\n",
       "          [ -6.5985],\n",
       "          [ -7.8488],\n",
       "          [-10.6923],\n",
       "          [ -5.9934],\n",
       "          [ -6.6459],\n",
       "          [-10.1199],\n",
       "          [ -8.5052],\n",
       "          [ -9.9167],\n",
       "          [ -9.4316],\n",
       "          [ -6.8350],\n",
       "          [ -8.2684],\n",
       "          [ -7.7582],\n",
       "          [ -7.1980],\n",
       "          [ -5.5753],\n",
       "          [ -5.4311],\n",
       "          [ -7.8286],\n",
       "          [ -8.5345],\n",
       "          [ -8.3323],\n",
       "          [ -6.1840],\n",
       "          [ -6.9092],\n",
       "          [ -7.6446],\n",
       "          [ -7.2592],\n",
       "          [ -4.2333],\n",
       "          [ -8.7673],\n",
       "          [ -6.1828],\n",
       "          [ -7.6069],\n",
       "          [ -8.8855],\n",
       "          [ -5.4820],\n",
       "          [ -8.7399],\n",
       "          [ -6.7306],\n",
       "          [ -7.0787],\n",
       "          [ -8.9869],\n",
       "          [ -9.6012],\n",
       "          [ -6.2930],\n",
       "          [ -9.1531],\n",
       "          [ -7.6430],\n",
       "          [ -2.8028],\n",
       "          [ -9.0986],\n",
       "          [ -7.1870],\n",
       "          [ -8.9850],\n",
       "          [ -6.0313],\n",
       "          [ -7.9300],\n",
       "          [ -6.5834],\n",
       "          [ -2.3184],\n",
       "          [ -7.3494],\n",
       "          [ -6.7242],\n",
       "          [ -6.0405],\n",
       "          [ -5.8553],\n",
       "          [-10.5172],\n",
       "          [ -6.8422],\n",
       "          [ -7.6528]]),\n",
       "  tensor([[-0.7595,  0.6505, -2.9836],\n",
       "          [-0.9796,  0.2009,  1.8556],\n",
       "          [-0.9910,  0.1337,  1.9630],\n",
       "          [-0.9905,  0.1378, -2.7961],\n",
       "          [-0.9734,  0.2289, -1.7116],\n",
       "          [-0.7736, -0.6336, -1.8607],\n",
       "          [-0.9997, -0.0258,  2.9437],\n",
       "          [-0.6674,  0.7447, -2.6376],\n",
       "          [-0.8259, -0.5638,  1.0357],\n",
       "          [-0.9840, -0.1783,  1.9381],\n",
       "          [-0.9698,  0.2437, -2.4157],\n",
       "          [-0.5750,  0.8182,  1.5105],\n",
       "          [-0.9784, -0.2069,  2.3366],\n",
       "          [-0.8615,  0.5077,  0.8336],\n",
       "          [-0.8866, -0.4626,  1.6436],\n",
       "          [-0.9811,  0.1934, -3.2455],\n",
       "          [-0.5817,  0.8134, -2.1984],\n",
       "          [-0.8629,  0.5054,  0.8355],\n",
       "          [-0.9894,  0.1449, -2.0452],\n",
       "          [-0.9060, -0.4232,  2.1006],\n",
       "          [-0.9983,  0.0590, -2.0052],\n",
       "          [-0.9997,  0.0232,  2.2179],\n",
       "          [-0.8355,  0.5494, -0.6519],\n",
       "          [-0.9270,  0.3752, -1.5074],\n",
       "          [-0.8593, -0.5115,  1.9991],\n",
       "          [-0.9169,  0.3992,  2.4385],\n",
       "          [-0.7471, -0.6647, -1.4463],\n",
       "          [-0.6568, -0.7541,  0.2872],\n",
       "          [-0.9006,  0.4347, -1.3021],\n",
       "          [-0.9216, -0.3883,  1.8021],\n",
       "          [-0.9512,  0.3087,  3.7715],\n",
       "          [-0.8257, -0.5641, -1.2630],\n",
       "          [-0.8812,  0.4727,  0.4840],\n",
       "          [-0.8805,  0.4741, -1.4324],\n",
       "          [-0.9190,  0.3943,  1.2457],\n",
       "          [-0.4747,  0.8802,  0.2658],\n",
       "          [-0.8885, -0.4589,  2.9424],\n",
       "          [-0.8028, -0.5962, -0.3365],\n",
       "          [-0.9423,  0.3348,  1.4145],\n",
       "          [-0.9902, -0.1398, -2.7990],\n",
       "          [-0.7204,  0.6935,  0.6806],\n",
       "          [-0.9918, -0.1278, -1.9260],\n",
       "          [-0.8680,  0.4966,  0.6981],\n",
       "          [-0.8623,  0.5064, -0.6091],\n",
       "          [-0.9919, -0.1274, -3.4040],\n",
       "          [-0.9999,  0.0103,  2.0452],\n",
       "          [-0.7273,  0.6863, -1.0935],\n",
       "          [-0.9454, -0.3259,  2.4708],\n",
       "          [-0.9487,  0.3161,  1.6749],\n",
       "          [-0.1107, -0.9939, -2.3262],\n",
       "          [-0.9639, -0.2664,  1.5497],\n",
       "          [-0.8229, -0.5682,  1.3464],\n",
       "          [-0.9940,  0.1096,  1.8491],\n",
       "          [-0.6794, -0.7338,  1.4713],\n",
       "          [-0.9560, -0.2935, -2.9979],\n",
       "          [-0.8343,  0.5513, -0.0264],\n",
       "          [ 0.0054, -1.0000, -1.8671],\n",
       "          [-0.8540, -0.5203,  1.3258],\n",
       "          [-0.7315, -0.6819,  1.7630],\n",
       "          [-0.8028, -0.5962, -1.7668],\n",
       "          [-0.7731,  0.6342,  3.0621],\n",
       "          [-0.9921,  0.1251, -2.5741],\n",
       "          [-0.8350,  0.5502, -0.5832],\n",
       "          [-0.7887, -0.6148,  2.3983]]),\n",
       "  tensor([[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]])))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        #样本池\n",
    "        self.datas = []\n",
    "\n",
    "    #向样本池中添加N条数据,删除M条最古老的数据\n",
    "    def update_data(self, agent):\n",
    "        #初始化游戏\n",
    "        state = env.reset()\n",
    "\n",
    "        #玩到游戏结束为止\n",
    "        over = False\n",
    "        while not over:\n",
    "            #根据当前状态得到一个动作\n",
    "            action = agent.get_action(state)\n",
    "\n",
    "            #执行动作,得到反馈\n",
    "            next_state, reward, over, _ = env.step([action])\n",
    "\n",
    "            #记录数据样本\n",
    "            self.datas.append((state, action, reward, next_state, over))\n",
    "\n",
    "            #更新游戏状态,开始下一个动作\n",
    "            state = next_state\n",
    "\n",
    "        #数据上限,超出时从最古老的开始删除\n",
    "        while len(self.datas) > 100000:\n",
    "            self.datas.pop(0)\n",
    "\n",
    "    #获取一批数据样本\n",
    "    def get_sample(self):\n",
    "        #从样本池中采样\n",
    "        samples = random.sample(self.datas, 64)\n",
    "\n",
    "        #[b, 3]\n",
    "        state = torch.FloatTensor([i[0] for i in samples]).reshape(-1, 3)\n",
    "        #[b, 1]\n",
    "        action = torch.FloatTensor([i[1] for i in samples]).reshape(-1, 1)\n",
    "        #[b, 1]\n",
    "        reward = torch.FloatTensor([i[2] for i in samples]).reshape(-1, 1)\n",
    "        #[b, 3]\n",
    "        next_state = torch.FloatTensor([i[3] for i in samples]).reshape(-1, 3)\n",
    "        #[b, 1]\n",
    "        over = torch.LongTensor([i[4] for i in samples]).reshape(-1, 1)\n",
    "\n",
    "        return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "data = Data()\n",
    "\n",
    "data.update_data(teacher), data.get_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1564.4733305140326\n",
      "10 -1349.7057880767052\n",
      "20 -276.4773210162449\n",
      "30 -154.95288842327392\n",
      "40 -173.47650027423828\n",
      "50 -150.9308895450593\n",
      "60 -139.05484829937376\n",
      "70 -132.53317162016853\n",
      "80 -139.60713337491046\n",
      "90 -113.30702211475793\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    #更新N条数据\n",
    "    data.update_data(teacher)\n",
    "\n",
    "    #每次更新过数据后,学习N次\n",
    "    for i in range(200):\n",
    "        teacher.train(*data.get_sample())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        test_result = sum([teacher.test(play=False) for _ in range(10)]) / 10\n",
    "        print(epoch, test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.29301917552948, -1608.7056849468304)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CQL(SAC):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _get_loss_value(self, model_value, target, state, action, next_state):\n",
    "        #计算value\n",
    "        value = model_value(state, action)\n",
    "\n",
    "        #计算loss,value的目标是要贴近target\n",
    "        loss_value = self.loss_fn(value, target)\n",
    "        \"\"\"以上与SAC相同,以下是CQL的部分\"\"\"\n",
    "\n",
    "        #把state复制5遍\n",
    "        #[b, 3] -> [b, 1, 3] -> [b, 5, 3]\n",
    "        state = state.unsqueeze(dim=1)\n",
    "        #[b, 1, 3] -> [b, 5, 3] -> [b*5, 3]\n",
    "        state = state.repeat(1, 5, 1).reshape(-1, 3)\n",
    "\n",
    "        #把next_state复制5遍\n",
    "        #[b, 3] -> [b, 1, 3]\n",
    "        next_state = next_state.unsqueeze(1)\n",
    "        #[b, 1, 3] -> [b, 5, 3] -> [b*5, 3]\n",
    "        next_state = next_state.repeat(1, 5, 1).reshape(-1, 3)\n",
    "\n",
    "        #随机一批动作,数量是数据量的5倍,值域在-1到1之间\n",
    "        rand_action = torch.empty([len(state), 1]).uniform_(-1, 1)\n",
    "\n",
    "        #计算state的动作和熵\n",
    "        #[b*5, 3] -> [b*5, 1],[b*5, 1]\n",
    "        curr_action, curr_entropy = self.model_action(state)\n",
    "\n",
    "        #计算next_state的动作和熵\n",
    "        #[b*5, 3] -> [b*5, 1],[b*5, 1]\n",
    "        next_action, next_entropy = self.model_action(next_state)\n",
    "\n",
    "        #计算三份动作分别的value\n",
    "        #[b*5, 1],[b*5, 1] -> [b*5, 1] -> [b, 5, 1]\n",
    "        value_rand = model_value(state, rand_action).reshape(-1, 5, 1)\n",
    "        #[b*5, 1],[b*5, 1] -> [b*5, 1] -> [b, 5, 1]\n",
    "        value_curr = model_value(state, curr_action).reshape(-1, 5, 1)\n",
    "        #[b*5, 1],[b*5, 1] -> [b*5, 1] -> [b, 5, 1]\n",
    "        value_next = model_value(state, next_action).reshape(-1, 5, 1)\n",
    "\n",
    "        #[b*5, 1] -> [b, 5, 1]\n",
    "        curr_entropy = curr_entropy.detach().reshape(-1, 5, 1)\n",
    "        next_entropy = next_entropy.detach().reshape(-1, 5, 1)\n",
    "\n",
    "        #三份value分别减去他们的熵\n",
    "        #[b, 5, 1]\n",
    "        value_rand -= math.log(0.5)\n",
    "        #[b, 5, 1]\n",
    "        value_curr -= curr_entropy\n",
    "        #[b, 5, 1]\n",
    "        value_next -= next_entropy\n",
    "\n",
    "        #拼合三份value\n",
    "        #[b, 5+5+5, 1] -> [b, 15, 1]\n",
    "        value_cat = torch.cat([value_rand, value_curr, value_next], dim=1)\n",
    "\n",
    "        #等价t.logsumexp(dim=1), t.exp().sum(dim=1).log()\n",
    "        #[b, 15, 1] -> [b, 1] -> scala\n",
    "        loss_cat = torch.logsumexp(value_cat, dim=1).mean()\n",
    "\n",
    "        #在原本的loss上增加上这一部分\n",
    "        #scala\n",
    "        loss_value += 5.0 * (loss_cat - value.mean())\n",
    "        \"\"\"CQL算法和SCA算法的差异到此为止\"\"\"\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "\n",
    "student = CQL()\n",
    "\n",
    "student.train(\n",
    "    torch.randn(5, 3),\n",
    "    torch.randn(5, 1),\n",
    "    torch.randn(5, 1),\n",
    "    torch.randn(5, 3),\n",
    "    torch.zeros(5, 1).long(),\n",
    ")\n",
    "\n",
    "student.get_action([1, 2, 3]), student.test(play=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OHoSU6uI-xIt",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1527.5907632873136\n",
      "2000 -729.0555861010984\n",
      "4000 -672.32353293761\n",
      "6000 -699.0669702224006\n",
      "8000 -1037.822313101092\n",
      "10000 -962.246586040171\n",
      "12000 -873.1725486281235\n",
      "14000 -903.4471762867737\n",
      "16000 -745.6717828916186\n",
      "18000 -573.2756042814575\n",
      "20000 -832.9871674255643\n",
      "22000 -633.3804968952729\n",
      "24000 -369.23875147937343\n",
      "26000 -450.5086301505472\n",
      "28000 -760.6431931818228\n",
      "30000 -621.2308004952586\n",
      "32000 -418.2006487468234\n",
      "34000 -338.4976686403578\n",
      "36000 -290.04307054652804\n",
      "38000 -381.1912511064991\n",
      "40000 -274.81631503148526\n",
      "42000 -416.8577286223734\n",
      "44000 -339.2985465931254\n",
      "46000 -279.06291128991927\n",
      "48000 -389.0839388652813\n"
     ]
    }
   ],
   "source": [
    "#训练N次,训练过程中不需要更新数据\n",
    "for i in range(50000):\n",
    "    #采样一批数据\n",
    "    student.train(*data.get_sample())\n",
    "\n",
    "    if i % 2000 == 0:\n",
    "        test_result = sum([student.test(play=False) for _ in range(10)]) / 10\n",
    "        print(i, test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-132.41053892908778"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.test(play=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第7章-DQN算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
