{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/core.py:26: UserWarning: \u001b[33mWARN: Gym minimally supports python 3.6 as the python foundation not longer supports the version, please update your version to 3.7+\u001b[0m\n",
      "  \"Gym minimally supports python 3.6 as the python foundation not longer supports the version, please update your version to 3.7+\"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  f\"The environment {id} is out of date. You should consider \"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  \"The argument mode in render method is deprecated; \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#创建环境\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "\n",
    "#打印游戏\n",
    "def show():\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个游戏的状态用4个数字表示,我也不知道这4个数字分别是什么意思,反正这4个数字就能描述游戏全部的状态\n",
      "state= [-0.0322979  -0.02575761  0.03993894  0.03090993]\n",
      "这个游戏一共有2个动作,不是0就是1\n",
      "env.action_space= Discrete(2)\n",
      "随机一个动作\n",
      "action= 0\n",
      "执行一个动作,得到下一个状态,奖励,是否结束\n",
      "state= [-0.03281305 -0.22142887  0.04055714  0.3359217 ]\n",
      "reward= 1.0\n",
      "over= False\n"
     ]
    }
   ],
   "source": [
    "#测试游戏环境\n",
    "def test_env():\n",
    "    state = env.reset()\n",
    "    print('这个游戏的状态用4个数字表示,我也不知道这4个数字分别是什么意思,反正这4个数字就能描述游戏全部的状态')\n",
    "    print('state=', state)\n",
    "    #state= [ 0.03490619  0.04873464  0.04908862 -0.00375859]\n",
    "\n",
    "    print('这个游戏一共有2个动作,不是0就是1')\n",
    "    print('env.action_space=', env.action_space)\n",
    "    #env.action_space= Discrete(2)\n",
    "\n",
    "    print('随机一个动作')\n",
    "    action = env.action_space.sample()\n",
    "    print('action=', action)\n",
    "    #action= 1\n",
    "\n",
    "    print('执行一个动作,得到下一个状态,奖励,是否结束')\n",
    "    state, reward, over, _ = env.step(action)\n",
    "\n",
    "    print('state=', state)\n",
    "    #state= [ 0.02018229 -0.16441101  0.01547085  0.2661691 ]\n",
    "\n",
    "    print('reward=', reward)\n",
    "    #reward= 1.0\n",
    "\n",
    "    print('over=', over)\n",
    "    #over= False\n",
    "\n",
    "\n",
    "test_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=128, out_features=2, bias=True)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=128, out_features=2, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#计算动作的模型,也是真正要用的模型\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 2),\n",
    ")\n",
    "\n",
    "#经验网络,用于评估一个状态的分数\n",
    "next_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 2),\n",
    ")\n",
    "\n",
    "#把model的参数复制给next_model\n",
    "next_model.load_state_dict(model.state_dict())\n",
    "\n",
    "model, next_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "#得到一个动作\n",
    "def get_action(state):\n",
    "    if random.random() < 0.01:\n",
    "        return random.choice([0, 1])\n",
    "\n",
    "    #走神经网络,得到一个动作\n",
    "    state = torch.FloatTensor(state).reshape(1, 4)\n",
    "\n",
    "    return model(state).argmax().item()\n",
    "\n",
    "\n",
    "get_action([0.0013847, -0.01194451, 0.04260966, 0.00688801])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 0), 200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#样本池\n",
    "datas = []\n",
    "\n",
    "\n",
    "#向样本池中添加N条数据,删除M条最古老的数据\n",
    "def update_data():\n",
    "    old_count = len(datas)\n",
    "\n",
    "    #玩到新增了N个数据为止\n",
    "    while len(datas) - old_count < 200:\n",
    "        #初始化游戏\n",
    "        state = env.reset()\n",
    "\n",
    "        #玩到游戏结束为止\n",
    "        over = False\n",
    "        while not over:\n",
    "            #根据当前状态得到一个动作\n",
    "            action = get_action(state)\n",
    "\n",
    "            #执行动作,得到反馈\n",
    "            next_state, reward, over, _ = env.step(action)\n",
    "\n",
    "            #记录数据样本\n",
    "            datas.append((state, action, reward, next_state, over))\n",
    "\n",
    "            #更新游戏状态,开始下一个动作\n",
    "            state = next_state\n",
    "\n",
    "    update_count = len(datas) - old_count\n",
    "    drop_count = max(len(datas) - 10000, 0)\n",
    "\n",
    "    #数据上限,超出时从最古老的开始删除\n",
    "    while len(datas) > 10000:\n",
    "        datas.pop(0)\n",
    "\n",
    "    return update_count, drop_count\n",
    "\n",
    "\n",
    "update_data(), len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811701593/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1208e+00, -5.8698e-01, -1.6706e-02, -5.9305e-02],\n",
       "         [-4.8614e-03,  1.4742e-01, -3.7731e-03, -2.1355e-01],\n",
       "         [ 1.1511e-03,  1.4817e-01, -1.2478e-02, -2.3001e-01],\n",
       "         [-5.1451e-01, -3.9776e-01, -4.3573e-03, -2.2192e-01],\n",
       "         [-3.9565e-01, -3.9709e-01,  1.4259e-02, -2.3670e-01],\n",
       "         [-2.2995e-02,  1.4952e-01,  2.4450e-02, -2.5993e-01],\n",
       "         [-1.2419e+00, -7.8057e-01, -7.2140e-03,  1.9946e-01],\n",
       "         [-1.2029e+00, -5.8577e-01, -7.7445e-03, -8.6094e-02],\n",
       "         [ 8.6021e-05, -4.7436e-02, -1.0830e-02,  7.3364e-02],\n",
       "         [-4.1544e-01, -3.9743e-01,  1.0734e-02, -2.2922e-01],\n",
       "         [-1.0109e+00, -3.9503e-01, -1.8839e-02, -2.8212e-01],\n",
       "         [-6.5669e-01, -5.9022e-01, -9.2182e-03,  1.2090e-02],\n",
       "         [ 1.3677e-02,  1.5247e-01, -4.0947e-02, -3.2515e-01],\n",
       "         [-5.2246e-01, -5.9282e-01, -8.7956e-03,  6.9389e-02],\n",
       "         [-4.3524e-01, -3.9767e-01,  7.4865e-03, -2.2390e-01],\n",
       "         [-1.5043e-01, -5.9863e-01, -5.1039e-02,  1.9790e-01],\n",
       "         [-4.9469e-01, -3.9786e-01, -1.4163e-03, -2.1964e-01],\n",
       "         [-1.4097e+00, -3.8895e-01, -2.9505e-02, -4.1645e-01],\n",
       "         [-2.1816e-01, -5.9453e-01, -3.7744e-02,  1.0713e-01],\n",
       "         [-7.7063e-01, -7.8437e-01,  2.3514e-03,  2.8326e-01],\n",
       "         [-2.8658e-03,  1.4759e-01, -6.4852e-03, -2.1727e-01],\n",
       "         [-7.3137e-01, -5.8930e-01, -2.9467e-03, -8.3129e-03],\n",
       "         [-3.9059e-03, -4.7775e-02, -5.3898e-03,  8.0832e-02],\n",
       "         [-1.0306e+00, -3.9441e-01, -2.4390e-02, -2.9574e-01],\n",
       "         [-1.8241e-01, -4.0144e-01, -4.5949e-02, -1.4078e-01],\n",
       "         [-4.7487e-01, -3.9788e-01,  1.4886e-03, -2.1920e-01],\n",
       "         [-5.8959e-03, -4.7831e-02, -2.8017e-03,  8.2081e-02],\n",
       "         [-8.6098e-01, -5.9045e-01,  1.3830e-02,  1.7112e-02],\n",
       "         [-1.4835e+00, -7.7596e-01, -4.1906e-02,  9.7851e-02],\n",
       "         [-9.9122e-01, -3.9550e-01, -1.3734e-02, -2.7177e-01],\n",
       "         [-4.6301e-01, -5.9300e-01,  1.9070e-05,  7.3477e-02],\n",
       "         [-1.2575e+00, -5.8534e-01, -3.2248e-03, -9.5488e-02],\n",
       "         [-1.4235e-01, -4.0425e-01, -4.9464e-02, -7.8773e-02],\n",
       "         [-2.5770e-01, -7.8819e-01, -2.6169e-02,  3.6775e-01],\n",
       "         [-1.1326e+00, -7.8186e-01, -1.7892e-02,  2.2806e-01],\n",
       "         [-1.2829e-02,  1.4750e-01,  6.7398e-03, -2.1514e-01],\n",
       "         [-5.3432e-01, -3.9757e-01, -7.4079e-03, -2.2606e-01],\n",
       "         [ 2.0941e-03, -4.7147e-02, -1.3818e-02,  6.6999e-02],\n",
       "         [-1.1599e+00, -7.8142e-01, -1.4735e-02,  2.1824e-01],\n",
       "         [-6.9684e-02, -6.0536e-01, -7.1999e-02,  3.4714e-01],\n",
       "         [-1.5106e+00, -7.7479e-01, -4.4104e-02,  7.2065e-02],\n",
       "         [-1.2302e+00, -5.8552e-01, -5.3836e-03, -9.1518e-02],\n",
       "         [-2.0923e-02,  1.4890e-01,  2.0059e-02, -2.4618e-01],\n",
       "         [-4.4320e-01, -5.9290e-01,  3.0084e-03,  7.1132e-02],\n",
       "         [-1.1052e+00, -7.8241e-01, -2.1507e-02,  2.4008e-01],\n",
       "         [ 1.8147e-02, -2.3496e-01, -5.6939e-02,  1.9882e-01],\n",
       "         [-3.5623e-01, -5.9185e-01,  5.4134e-03,  4.8062e-02],\n",
       "         [-9.3992e-01, -5.9122e-01, -5.0591e-03,  3.4194e-02],\n",
       "         [-8.6399e-03, -2.2715e-01, -6.1812e-02,  2.6131e-02],\n",
       "         [-1.3395e+00, -5.8515e-01,  2.5880e-03, -9.9684e-02],\n",
       "         [ 7.9982e-03, -3.7531e-02, -5.1902e-02, -1.4532e-01],\n",
       "         [-3.4049e-01, -7.8699e-01, -1.4104e-03,  3.4119e-01],\n",
       "         [-3.1291e-01, -7.8716e-01, -9.2929e-03,  3.4486e-01],\n",
       "         [-3.4065e-03, -2.2879e-01, -5.8097e-02,  6.2339e-02],\n",
       "         [-8.7279e-01, -3.9553e-01,  1.4172e-02, -2.7118e-01],\n",
       "         [-9.2017e-01, -5.9123e-01, -5.7537e-04,  3.4340e-02],\n",
       "         [-1.6846e-02,  1.4801e-01,  1.2741e-02, -2.2640e-01],\n",
       "         [-8.8070e-01, -5.9085e-01,  8.7485e-03,  2.5944e-02],\n",
       "         [-7.9810e-01, -7.8452e-01,  7.8431e-03,  2.8653e-01],\n",
       "         [-1.6533e+00, -7.6726e-01, -6.0870e-02, -9.4303e-02],\n",
       "         [-9.5174e-01, -3.9603e-01, -4.3752e-03, -2.6008e-01],\n",
       "         [-1.4719e+00, -5.8140e-01, -3.8255e-02, -1.8252e-01],\n",
       "         [-4.4456e-02, -2.1932e-01, -6.9270e-02, -1.4684e-01],\n",
       "         [-1.4447e+00, -5.8252e-01, -3.7552e-02, -1.5788e-01]]),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[-1.1326e+00, -7.8186e-01, -1.7892e-02,  2.2806e-01],\n",
       "         [-1.9130e-03, -4.7644e-02, -8.0441e-03,  7.7944e-02],\n",
       "         [ 4.1145e-03, -4.6772e-02, -1.7078e-02,  5.8710e-02],\n",
       "         [-5.2246e-01, -5.9282e-01, -8.7956e-03,  6.9389e-02],\n",
       "         [-4.0359e-01, -5.9241e-01,  9.5252e-03,  6.0447e-02],\n",
       "         [-2.0004e-02, -4.5940e-02,  1.9252e-02,  4.0363e-02],\n",
       "         [-1.2575e+00, -5.8534e-01, -3.2248e-03, -9.5488e-02],\n",
       "         [-1.2146e+00, -7.8078e-01, -9.4663e-03,  2.0414e-01],\n",
       "         [-8.6270e-04,  1.4784e-01, -9.3632e-03, -2.2272e-01],\n",
       "         [-4.2339e-01, -5.9270e-01,  6.1498e-03,  6.6834e-02],\n",
       "         [-1.0188e+00, -5.8988e-01, -2.4481e-02,  4.5663e-03],\n",
       "         [-6.6849e-01, -3.9497e-01, -8.9765e-03, -2.8349e-01],\n",
       "         [ 1.6727e-02, -4.2043e-02, -4.7450e-02, -4.5654e-02],\n",
       "         [-5.3432e-01, -3.9757e-01, -7.4079e-03, -2.2606e-01],\n",
       "         [-4.4320e-01, -5.9290e-01,  3.0084e-03,  7.1132e-02],\n",
       "         [-1.6240e-01, -4.0282e-01, -4.7081e-02, -1.1043e-01],\n",
       "         [-5.0265e-01, -5.9296e-01, -5.8092e-03,  7.2593e-02],\n",
       "         [-1.4174e+00, -5.8364e-01, -3.7834e-02, -1.3321e-01],\n",
       "         [-2.3005e-01, -7.8909e-01, -3.5602e-02,  3.8767e-01],\n",
       "         [-7.8632e-01, -5.8928e-01,  8.0166e-03, -8.6764e-03],\n",
       "         [ 8.6021e-05, -4.7436e-02, -1.0830e-02,  7.3364e-02],\n",
       "         [-7.4316e-01, -7.8438e-01, -3.1129e-03,  2.8344e-01],\n",
       "         [-4.8614e-03,  1.4742e-01, -3.7731e-03, -2.1355e-01],\n",
       "         [-1.0385e+00, -5.8918e-01, -3.0304e-02, -1.0847e-02],\n",
       "         [-1.9043e-01, -5.9588e-01, -4.8765e-02,  1.3706e-01],\n",
       "         [-4.8283e-01, -5.9302e-01, -2.8954e-03,  7.3953e-02],\n",
       "         [-6.8525e-03,  1.4733e-01, -1.1601e-03, -2.1148e-01],\n",
       "         [-8.7279e-01, -3.9553e-01,  1.4172e-02, -2.7118e-01],\n",
       "         [-1.4990e+00, -5.8026e-01, -3.9949e-02, -2.0775e-01],\n",
       "         [-9.9913e-01, -5.9042e-01, -1.9170e-02,  1.6553e-02],\n",
       "         [-4.7487e-01, -3.9788e-01,  1.4886e-03, -2.1920e-01],\n",
       "         [-1.2693e+00, -7.8042e-01, -5.1345e-03,  1.9618e-01],\n",
       "         [-1.5043e-01, -5.9863e-01, -5.1039e-02,  1.9790e-01],\n",
       "         [-2.7346e-01, -5.9271e-01, -1.8814e-02,  6.6933e-02],\n",
       "         [-1.1482e+00, -5.8649e-01, -1.3331e-02, -7.0211e-02],\n",
       "         [-9.8787e-03, -4.7722e-02,  2.4370e-03,  7.9663e-02],\n",
       "         [-5.4227e-01, -5.9259e-01, -1.1929e-02,  6.4281e-02],\n",
       "         [ 1.1511e-03,  1.4817e-01, -1.2478e-02, -2.3001e-01],\n",
       "         [-1.1755e+00, -5.8609e-01, -1.0370e-02, -7.9058e-02],\n",
       "         [-8.1792e-02, -4.0930e-01, -6.5057e-02,  3.2646e-02],\n",
       "         [-1.5261e+00, -5.7906e-01, -4.2662e-02, -2.3420e-01],\n",
       "         [-1.2419e+00, -7.8057e-01, -7.2140e-03,  1.9946e-01],\n",
       "         [-1.7945e-02, -4.6502e-02,  1.5135e-02,  5.2757e-02],\n",
       "         [-4.5505e-01, -3.9782e-01,  4.4311e-03, -2.2060e-01],\n",
       "         [-1.1208e+00, -5.8698e-01, -1.6706e-02, -5.9305e-02],\n",
       "         [ 1.3448e-02, -3.9074e-02, -5.2962e-02, -1.1126e-01],\n",
       "         [-3.6807e-01, -7.8705e-01,  6.3746e-03,  3.4245e-01],\n",
       "         [-9.5174e-01, -3.9603e-01, -4.3752e-03, -2.6008e-01],\n",
       "         [-1.3183e-02, -3.1195e-02, -6.1289e-02, -2.8540e-01],\n",
       "         [-1.3512e+00, -3.9007e-01,  5.9433e-04, -3.9155e-01],\n",
       "         [ 7.2476e-03, -2.3187e-01, -5.4809e-02,  1.3055e-01],\n",
       "         [-3.5623e-01, -5.9185e-01,  5.4134e-03,  4.8062e-02],\n",
       "         [-3.2865e-01, -5.9191e-01, -2.3957e-03,  4.9263e-02],\n",
       "         [-7.9823e-03, -3.2881e-02, -5.6850e-02, -2.4809e-01],\n",
       "         [-8.8070e-01, -5.9085e-01,  8.7485e-03,  2.5944e-02],\n",
       "         [-9.3200e-01, -3.9610e-01,  1.1143e-04, -2.5852e-01],\n",
       "         [-1.3886e-02, -4.7296e-02,  8.2127e-03,  7.0271e-02],\n",
       "         [-8.9251e-01, -3.9585e-01,  9.2674e-03, -2.6397e-01],\n",
       "         [-8.1379e-01, -5.8951e-01,  1.3574e-02, -3.6739e-03],\n",
       "         [-1.6686e+00, -9.6146e-01, -6.2756e-02,  1.7857e-01],\n",
       "         [-9.5967e-01, -5.9109e-01, -9.5768e-03,  3.1219e-02],\n",
       "         [-1.4835e+00, -7.7596e-01, -4.1906e-02,  9.7851e-02],\n",
       "         [-4.8843e-02, -4.1339e-01, -7.2207e-02,  1.2321e-01],\n",
       "         [-1.4563e+00, -7.7708e-01, -4.0710e-02,  1.2272e-01]]),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取一批数据样本\n",
    "def get_sample():\n",
    "    #从样本池中采样\n",
    "    samples = random.sample(datas, 64)\n",
    "\n",
    "    #[b, 4]\n",
    "    state = torch.FloatTensor([i[0] for i in samples]).reshape(-1, 4)\n",
    "    #[b, 1]\n",
    "    action = torch.LongTensor([i[1] for i in samples]).reshape(-1, 1)\n",
    "    #[b, 1]\n",
    "    reward = torch.FloatTensor([i[2] for i in samples]).reshape(-1, 1)\n",
    "    #[b, 4]\n",
    "    next_state = torch.FloatTensor([i[3] for i in samples]).reshape(-1, 4)\n",
    "    #[b, 1]\n",
    "    over = torch.LongTensor([i[4] for i in samples]).reshape(-1, 1)\n",
    "\n",
    "    return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "state, action, reward, next_state, over = get_sample()\n",
    "\n",
    "state, action, reward, next_state, over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_value(state, action):\n",
    "    #使用状态计算出动作的logits\n",
    "    #[b, 4] -> [b, 2]\n",
    "    value = model(state)\n",
    "\n",
    "    #根据实际使用的action取出每一个值\n",
    "    #这个值就是模型评估的在该状态下,执行动作的分数\n",
    "    #在执行动作前,显然并不知道会得到的反馈和next_state\n",
    "    #所以这里不能也不需要考虑next_state和reward\n",
    "    #[b, 2] -> [b, 1]\n",
    "    value = value.gather(dim=1, index=action)\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "get_value(state, action).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_target(reward, next_state, over):\n",
    "    #上面已经把模型认为的状态下执行动作的分数给评估出来了\n",
    "    #下面使用next_state和reward计算真实的分数\n",
    "    #针对一个状态,它到底应该多少分,可以使用以往模型积累的经验评估\n",
    "    #这也是没办法的办法,因为显然没有精确解,这里使用延迟更新的next_model评估\n",
    "\n",
    "    #使用next_state计算下一个状态的分数\n",
    "    #[b, 4] -> [b, 2]\n",
    "    with torch.no_grad():\n",
    "        target = next_model(next_state)\n",
    "\n",
    "    #取所有动作中分数最大的\n",
    "    #[b, 2] -> [b, 1]\n",
    "    target = target.max(dim=1)[0]\n",
    "    target = target.reshape(-1, 1)\n",
    "\n",
    "    #下一个状态的分数乘以一个系数,相当于权重\n",
    "    target *= 0.98\n",
    "\n",
    "    #如果next_state已经游戏结束,则next_state的分数是0\n",
    "    #因为如果下一步已经游戏结束,显然不需要再继续玩下去,也就不需要考虑next_state了.\n",
    "    #[b, 1] * [b, 1] -> [b, 1]\n",
    "    target *= (1 - over)\n",
    "\n",
    "    #加上reward就是最终的分数\n",
    "    #[b, 1] + [b, 1] -> [b, 1]\n",
    "    target += reward\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "get_target(reward, next_state, over).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "\n",
    "def test(play):\n",
    "    #初始化游戏\n",
    "    state = env.reset()\n",
    "\n",
    "    #记录反馈值的和,这个值越大越好\n",
    "    reward_sum = 0\n",
    "\n",
    "    #玩到游戏结束为止\n",
    "    over = False\n",
    "    while not over:\n",
    "        #根据当前状态得到一个动作\n",
    "        action = get_action(state)\n",
    "\n",
    "        #执行动作,得到反馈\n",
    "        state, reward, over, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "\n",
    "        #打印动画\n",
    "        if play and random.random() < 0.2:  #跳帧\n",
    "            display.clear_output(wait=True)\n",
    "            show()\n",
    "\n",
    "    return reward_sum\n",
    "\n",
    "\n",
    "test(play=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OHoSU6uI-xIt",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 400 200 0 9.4\n",
      "50 10000 200 200 200.0\n",
      "100 10000 200 200 200.0\n",
      "150 10000 200 200 200.0\n",
      "200 10000 384 384 185.9\n",
      "250 10000 375 375 176.9\n",
      "300 10000 200 200 200.0\n",
      "350 10000 200 200 186.05\n",
      "400 10000 200 200 200.0\n",
      "450 10000 200 200 200.0\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    #训练N次\n",
    "    for epoch in range(500):\n",
    "        #更新N条数据\n",
    "        update_count, drop_count = update_data()\n",
    "\n",
    "        #每次更新过数据后,学习N次\n",
    "        for i in range(200):\n",
    "            #采样一批数据\n",
    "            state, action, reward, next_state, over = get_sample()\n",
    "\n",
    "            #计算一批样本的value和target\n",
    "            value = get_value(state, action)\n",
    "            target = get_target(reward, next_state, over)\n",
    "\n",
    "            #更新参数\n",
    "            loss = loss_fn(value, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #把model的参数复制给next_model\n",
    "            if (i + 1) % 10 == 0:\n",
    "                next_model.load_state_dict(model.state_dict())\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            test_result = sum([test(play=False) for _ in range(20)]) / 20\n",
    "            print(epoch, len(datas), update_count, drop_count, test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(play=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第7章-DQN算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
