{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Conda\\envs\\RL_Simple\\lib\\site-packages\\gym\\core.py:26: UserWarning: \u001b[33mWARN: Gym minimally supports python 3.6 as the python foundation not longer supports the version, please update your version to 3.7+\u001b[0m\n",
      "  \"Gym minimally supports python 3.6 as the python foundation not longer supports the version, please update your version to 3.7+\"\n",
      "d:\\Conda\\envs\\RL_Simple\\lib\\site-packages\\gym\\envs\\registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  f\"The environment {id} is out of date. You should consider \"\n",
      "d:\\Conda\\envs\\RL_Simple\\lib\\site-packages\\gym\\core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "d:\\Conda\\envs\\RL_Simple\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "d:\\Conda\\envs\\RL_Simple\\lib\\site-packages\\gym\\core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  \"The argument mode in render method is deprecated; \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#创建环境\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "\n",
    "#打印游戏\n",
    "def show():\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6480, 0.3520],\n",
       "         [0.5218, 0.4782]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[ 0.1199],\n",
       "         [-0.0570]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#定义模型\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 2),\n",
    "    torch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "model_td = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 1),\n",
    ")\n",
    "\n",
    "model(torch.randn(2, 4)), model_td(torch.randn(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "#得到一个动作\n",
    "def get_action(state):\n",
    "    state = torch.FloatTensor(state).reshape(1, 4)\n",
    "    #[1, 4] -> [1, 2]\n",
    "    prob = model(state)\n",
    "\n",
    "    #根据概率选择一个动作\n",
    "    action = random.choices(range(2), weights=prob[0].tolist(), k=1)[0]\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "get_action([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Conda\\envs\\RL_Simple\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0309,  0.0185,  0.0394, -0.0453],\n",
       "         [ 0.0312, -0.1772,  0.0385,  0.2595],\n",
       "         [ 0.0277, -0.3728,  0.0437,  0.5641],\n",
       "         [ 0.0202, -0.1783,  0.0549,  0.2855],\n",
       "         [ 0.0167, -0.3742,  0.0607,  0.5950],\n",
       "         [ 0.0092, -0.5701,  0.0726,  0.9061],\n",
       "         [-0.0022, -0.7661,  0.0907,  1.2207],\n",
       "         [-0.0175, -0.9623,  0.1151,  1.5403],\n",
       "         [-0.0368, -1.1586,  0.1459,  1.8666],\n",
       "         [-0.0599, -0.9653,  0.1832,  1.6226]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0]]),\n",
       " tensor([[ 0.0312, -0.1772,  0.0385,  0.2595],\n",
       "         [ 0.0277, -0.3728,  0.0437,  0.5641],\n",
       "         [ 0.0202, -0.1783,  0.0549,  0.2855],\n",
       "         [ 0.0167, -0.3742,  0.0607,  0.5950],\n",
       "         [ 0.0092, -0.5701,  0.0726,  0.9061],\n",
       "         [-0.0022, -0.7661,  0.0907,  1.2207],\n",
       "         [-0.0175, -0.9623,  0.1151,  1.5403],\n",
       "         [-0.0368, -1.1586,  0.1459,  1.8666],\n",
       "         [-0.0599, -0.9653,  0.1832,  1.6226],\n",
       "         [-0.0793, -1.1621,  0.2157,  1.9663]]),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data():\n",
    "    states = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    next_states = []\n",
    "    overs = []\n",
    "\n",
    "    #初始化游戏\n",
    "    state = env.reset()\n",
    "\n",
    "    #玩到游戏结束为止\n",
    "    over = False\n",
    "    while not over:\n",
    "        #根据当前状态得到一个动作\n",
    "        action = get_action(state)\n",
    "\n",
    "        #执行动作,得到反馈\n",
    "        next_state, reward, over, _ = env.step(action)\n",
    "\n",
    "        #记录数据样本\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        next_states.append(next_state)\n",
    "        overs.append(over)\n",
    "\n",
    "        #更新游戏状态,开始下一个动作\n",
    "        state = next_state\n",
    "\n",
    "    #[b, 4]\n",
    "    states = torch.FloatTensor(states).reshape(-1, 4)\n",
    "    #[b, 1]\n",
    "    rewards = torch.FloatTensor(rewards).reshape(-1, 1)\n",
    "    #[b, 1]\n",
    "    actions = torch.LongTensor(actions).reshape(-1, 1)\n",
    "    #[b, 4]\n",
    "    next_states = torch.FloatTensor(next_states).reshape(-1, 4)\n",
    "    #[b, 1]\n",
    "    overs = torch.LongTensor(overs).reshape(-1, 1)\n",
    "\n",
    "    return states, rewards, actions, next_states, overs\n",
    "\n",
    "\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "\n",
    "def test(play):\n",
    "    #初始化游戏\n",
    "    state = env.reset()\n",
    "\n",
    "    #记录反馈值的和,这个值越大越好\n",
    "    reward_sum = 0\n",
    "\n",
    "    #玩到游戏结束为止\n",
    "    over = False\n",
    "    while not over:\n",
    "        #根据当前状态得到一个动作\n",
    "        action = get_action(state)\n",
    "\n",
    "        #执行动作,得到反馈\n",
    "        state, reward, over, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "\n",
    "        #打印动画\n",
    "        if play and random.random() < 0.2:  #跳帧\n",
    "            display.clear_output(wait=True)\n",
    "            show()\n",
    "\n",
    "    return reward_sum\n",
    "\n",
    "\n",
    "test(play=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.090483997483998, 8.690100963999999, 8.260044, 6.724, 4.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#优势函数\n",
    "def get_advantages(deltas):\n",
    "    advantages = []\n",
    "\n",
    "    #反向遍历deltas\n",
    "    s = 0.0\n",
    "    for delta in deltas[::-1]:\n",
    "        s = 0.98 * 0.95 * s + delta\n",
    "        advantages.append(s)\n",
    "\n",
    "    #逆序\n",
    "    advantages.reverse()\n",
    "    return advantages\n",
    "\n",
    "\n",
    "get_advantages(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8251,
     "status": "ok",
     "timestamp": 1650011468229,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "BQXVYW2T_DcQ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 18.7\n",
      "50 136.8\n",
      "100 135.6\n",
      "150 200.0\n",
      "200 200.0\n",
      "250 200.0\n",
      "300 200.0\n",
      "350 200.0\n",
      "400 200.0\n",
      "450 200.0\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    optimizer_td = torch.optim.Adam(model_td.parameters(), lr=1e-2)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    #玩N局游戏,每局游戏训练M次\n",
    "    for epoch in range(500):\n",
    "        #玩一局游戏,得到数据\n",
    "        #states -> [b, 4]\n",
    "        #rewards -> [b, 1]\n",
    "        #actions -> [b, 1]\n",
    "        #next_states -> [b, 4]\n",
    "        #overs -> [b, 1]\n",
    "        states, rewards, actions, next_states, overs = get_data()\n",
    "\n",
    "        #计算values和targets\n",
    "        #[b, 4] -> [b, 1]\n",
    "        values = model_td(states)\n",
    "\n",
    "        #[b, 4] -> [b, 1]\n",
    "        targets = model_td(next_states).detach()\n",
    "        targets = targets * 0.98\n",
    "        targets *= (1 - overs)\n",
    "        targets += rewards\n",
    "\n",
    "        #计算优势,这里的advantages有点像是策略梯度里的reward_sum\n",
    "        #只是这里计算的不是reward,而是target和value的差\n",
    "        #[b, 1]\n",
    "        deltas = (targets - values).squeeze(dim=1).tolist()\n",
    "        advantages = get_advantages(deltas)\n",
    "        advantages = torch.FloatTensor(advantages).reshape(-1, 1)\n",
    "\n",
    "        #取出每一步动作的概率\n",
    "        #[b, 2] -> [b, 2] -> [b, 1]\n",
    "        old_probs = model(states)\n",
    "        old_probs = old_probs.gather(dim=1, index=actions)\n",
    "        old_probs = old_probs.detach()\n",
    "\n",
    "        #每批数据反复训练10次\n",
    "        for _ in range(10):\n",
    "            #重新计算每一步动作的概率\n",
    "            #[b, 4] -> [b, 2]\n",
    "            new_probs = model(states)\n",
    "            #[b, 2] -> [b, 1]\n",
    "            new_probs = new_probs.gather(dim=1, index=actions)\n",
    "            new_probs = new_probs\n",
    "\n",
    "            #求出概率的变化\n",
    "            #[b, 1] - [b, 1] -> [b, 1]\n",
    "            ratios = new_probs / old_probs\n",
    "\n",
    "            #计算截断的和不截断的两份loss,取其中小的\n",
    "            #[b, 1] * [b, 1] -> [b, 1]\n",
    "            surr1 = ratios * advantages\n",
    "            #[b, 1] * [b, 1] -> [b, 1]\n",
    "            surr2 = torch.clamp(ratios, 0.8, 1.2) * advantages\n",
    "\n",
    "            loss = -torch.min(surr1, surr2)\n",
    "            loss = loss.mean()\n",
    "\n",
    "            #重新计算value,并计算时序差分loss\n",
    "            values = model_td(states)\n",
    "            loss_td = loss_fn(values, targets)\n",
    "\n",
    "            #更新参数\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer_td.zero_grad()\n",
    "            loss_td.backward()\n",
    "            optimizer_td.step()\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            test_result = sum([test(play=False) for _ in range(10)]) / 10\n",
    "            print(epoch, test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(play=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第9章-策略梯度算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('RL_Simple')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "6925958b004b98bc0512a6d71e5da00858331a32f66ed7f503cad179ff8aa782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
